{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0627f37",
   "metadata": {},
   "source": [
    "# Трекинг класса человек  \n",
    "\n",
    "### Вывод информации на экран"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccc7cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55975817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка добученной модели YOLOv8\n",
    "model = YOLO(\"runs/train/yolov10n_bus_stop_finetuned5/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f589686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 9.9ms\n",
      "Speed: 1.7ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Количество людей на фото: 0\n"
     ]
    }
   ],
   "source": [
    "# Загрузка изображения\n",
    "#image = cv2.imread('2.png')\n",
    "image = cv2.imread('C:/Users/Egor/Desktop/ss/AI-Flow-Detecting/ai-core/dataset/test/images/20250811_221824.jpg')\n",
    "\n",
    "# Детекция людей (класс '0' в COCO = человек)\n",
    "results = model(image, classes=[0])  \n",
    "\n",
    "# Визуализация результатов\n",
    "annotated_image = results[0].plot()  # Рисует bounding boxes\n",
    "cv2.imshow('Detected People', annotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Подсчёт количества людей\n",
    "people_count = len(results[0].boxes)\n",
    "print(f\"Количество людей на фото: {people_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ba2d08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Видеопоток запущен. Детекция людей через YOLOv8...\n",
      "⏹️ Работа завершена.\n"
     ]
    }
   ],
   "source": [
    "# Загрузка модели YOLOv8 (nano — быстро, подходит для реального времени)\n",
    "#model = YOLO('yolov10n.pt')\n",
    "\n",
    "# URL видеопотока (убраны лишние пробелы в конце!)\n",
    "# https://restreamer.vms.evo73.ru/918335436b92ac26/stream.m3u8\n",
    "# https://restreamer.vms.evo73.ru/24c3036fe19a150a/stream.m3u8\n",
    "stream_url = \"https://restreamer.vms.evo73.ru/918335436b92ac26/stream.m3u8\"\n",
    "\n",
    "# Открываем видеопоток\n",
    "cap = cv2.VideoCapture(stream_url)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Ошибка: Не удалось открыть видеопоток. Проверь URL и соединение.\")\n",
    "    exit()\n",
    "\n",
    "print(\"✅ Видеопоток запущен. Детекция людей через YOLOv8...\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"⚠️ Не удалось получить кадр. Поток может быть разорван.\")\n",
    "        break\n",
    "\n",
    "    # Детекция ТОЛЬКО людей (класс 0 в COCO)\n",
    "    results = model.predict(frame, classes=[0], conf=0.5, verbose=False)\n",
    "\n",
    "    # Наносим bounding boxes и метки\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Подсчёт обнаруженных людей\n",
    "    people_count = len(results[0].boxes)\n",
    "    cv2.putText(annotated_frame, f'Людей: {people_count}', (10, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Показываем кадр\n",
    "    cv2.imshow('YOLOv8 — Детекция людей в реальном времени', annotated_frame)\n",
    "\n",
    "    # Выход по клавише 'q' или пробелу\n",
    "    if cv2.waitKey(1) & 0xFF in [ord('q'), ord(' ')]:\n",
    "        break\n",
    "\n",
    "# Освобождение ресурсов\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"⏹️ Работа завершена.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b96690a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv10m summary (fused): 136 layers, 15,316,063 parameters, 0 gradients, 58.9 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import random\n",
    "\n",
    "def process_video_with_tracking(model, input_source, show_video=True, save_video=False, output_video_path=\"output_video.mp4\"):\n",
    "    \"\"\"\n",
    "    Функция для обработки видео с детекцией объектов и трекингом.\n",
    "\n",
    "    Аргументы:\n",
    "    model: Загруженная модель YOLO\n",
    "    input_source: Путь к видеофайлу или URL видеопотока\n",
    "    show_video: Показывать ли видео в реальном времени\n",
    "    save_video: Сохранять ли результат в файл\n",
    "    output_video_path: Путь для сохранения выходного видео\n",
    "    \"\"\"\n",
    "\n",
    "    # Открыть источник видео (видеофайл или поток)\n",
    "    cap = cv2.VideoCapture(input_source)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        raise Exception(\"Ошибка: Не удалось открыть видео или поток.\")\n",
    "\n",
    "    # Получить параметры видео\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Настройка записи видео если нужно сохранять\n",
    "    if save_video:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"⚠️ Не удалось получить кадр. Поток может быть прерван.\")\n",
    "            break\n",
    "\n",
    "        # Детекция объектов\n",
    "        results = model.track(\n",
    "            frame,\n",
    "            iou=0.4,           # Порог пересечения для трекинга\n",
    "            conf=0.5,          # Порог уверенности\n",
    "            persist=True,      # Сохранять треки между кадрами\n",
    "            imgsz=608,         # Размер изображения для обработки\n",
    "            verbose=False,     # Не выводить подробную информацию\n",
    "            tracker=\"botsort.yaml\"  # Тип трекера\n",
    "        )\n",
    "\n",
    "        # Наносим bounding boxes и метки\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Подсчёт обнаруженных людей (класс 0)\n",
    "        people_count = len(results[0].boxes)\n",
    "        cv2.putText(annotated_frame, f'Людей: {people_count}', (10, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Если есть трекинг, добавляем ID объектов\n",
    "        if results[0].boxes.id is not None:\n",
    "            boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)\n",
    "            ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
    "\n",
    "            for box, id in zip(boxes, ids):\n",
    "                # Генерация случайного цвета для каждого объекта на основе его ID\n",
    "                random.seed(int(id))\n",
    "                color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "\n",
    "                # Рисование прямоугольника\n",
    "                cv2.rectangle(annotated_frame, (box[0], box[1]), (box[2], box[3]), color, 2)\n",
    "                # Добавление текста с ID\n",
    "                cv2.putText(\n",
    "                    annotated_frame,\n",
    "                    f\"Id {id}\",\n",
    "                    (box[0], box[1]),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    (0, 255, 255),\n",
    "                    2,\n",
    "                )\n",
    "\n",
    "        # Сохранение кадра в файл если нужно\n",
    "        if save_video:\n",
    "            out.write(annotated_frame)\n",
    "\n",
    "        # Показ кадра если нужно\n",
    "        if show_video:\n",
    "            # Уменьшение размера для удобства просмотра\n",
    "            annotated_frame = cv2.resize(annotated_frame, (0, 0), fx=0.75, fy=0.75)\n",
    "            cv2.imshow(\"YOLOv8 — Обнаружение людей в реальном времени\", annotated_frame)\n",
    "\n",
    "        # Выход по нажатию клавиши 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    # Освобождение ресурсов\n",
    "    cap.release()\n",
    "    if save_video:\n",
    "        out.release()\n",
    "\n",
    "    # Закрытие всех окон OpenCV\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Загрузка модели YOLOv8\n",
    "model = YOLO('runs/train/yolov10n_bus_stop_finetuned5/weights/best.pt')\n",
    "model.fuse()  # Оптимизация модели\n",
    "\n",
    "# Путь к видео или URL потока\n",
    "# input_source = \"test.mp4\"  # Локальный файл\n",
    "input_source = \"https://restreamer.vms.evo73.ru/918335436b92ac26/stream.m3u8\"  # Видеопоток\n",
    "\n",
    "# Запуск обработки видео\n",
    "process_video_with_tracking(\n",
    "    model,\n",
    "    input_source,\n",
    "    show_video=True,\n",
    "    save_video=False,\n",
    "    output_video_path=\"output_video.mp4\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
