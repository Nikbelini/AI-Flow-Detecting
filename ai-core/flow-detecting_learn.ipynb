{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c3bd6b",
   "metadata": {},
   "source": [
    "# Предобученная модель YOLO для детектинга людей  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc2dd971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Загрузка предобученной модели YOLOv8 (можно 'yolov8n.pt', 'yolov8s.pt' и т.д.)\n",
    "model = YOLO('yolov10n.pt')  # nano-версия (быстрая, но менее точная)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ccd8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 147.3ms\n",
      "Speed: 4.6ms preprocess, 147.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# Загрузка изображения\n",
    "#image = cv2.imread('2.png')\n",
    "image = cv2.imread('E://AIM/AI-Flow-Detecting/ai-core/data/2025-08-08_11-29-04.png')\n",
    "\n",
    "# Детекция людей (класс '0' в COCO = человек)\n",
    "results = model(image, classes=[0])  \n",
    "\n",
    "# Визуализация результатов\n",
    "annotated_image = results[0].plot()  # Рисует bounding boxes\n",
    "cv2.imshow('Detected People', annotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Подсчёт количества людей\n",
    "people_count = len(results[0].boxes)\n",
    "print(f\"Количество людей на фото: {people_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2747fe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Видеопоток запущен. Детекция людей через YOLOv8...\n",
      "⏹️ Работа завершена.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Загрузка модели YOLOv8 (nano — быстро, подходит для реального времени)\n",
    "model = YOLO('yolov10n.pt')\n",
    "\n",
    "# URL видеопотока (убраны лишние пробелы в конце!)\n",
    "stream_url = \"https://restreamer.vms.evo73.ru/918335436b92ac26/stream.m3u8\"\n",
    "\n",
    "# Открываем видеопоток\n",
    "cap = cv2.VideoCapture(stream_url)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Ошибка: Не удалось открыть видеопоток. Проверь URL и соединение.\")\n",
    "    exit()\n",
    "\n",
    "print(\"✅ Видеопоток запущен. Детекция людей через YOLOv8...\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"⚠️ Не удалось получить кадр. Поток может быть разорван.\")\n",
    "        break\n",
    "\n",
    "    # Детекция ТОЛЬКО людей (класс 0 в COCO)\n",
    "    results = model.predict(frame, classes=[0], conf=0.5, verbose=False)\n",
    "\n",
    "    # Наносим bounding boxes и метки\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Подсчёт обнаруженных людей\n",
    "    people_count = len(results[0].boxes)\n",
    "    cv2.putText(annotated_frame, f'Людей: {people_count}', (10, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Показываем кадр\n",
    "    cv2.imshow('YOLOv8 — Детекция людей в реальном времени', annotated_frame)\n",
    "\n",
    "    # Выход по клавише 'q' или пробелу\n",
    "    if cv2.waitKey(1) & 0xFF in [ord('q'), ord(' ')]:\n",
    "        break\n",
    "\n",
    "# Освобождение ресурсов\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"⏹️ Работа завершена.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9ee499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "#plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Display image and videos\n",
    "import IPython\n",
    "from IPython.display import Video, display\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import urllib.request \n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a612e61",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      5\u001b[39m os.makedirs(\u001b[33m\"\u001b[39m\u001b[33mdata/images\u001b[39m\u001b[33m\"\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m cap = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVideoCapture\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://restreamer.vms.evo73.ru/918335436b92ac26/stream.m3u8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m count = \u001b[32m0\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mСбор кадров начат... Нажми \u001b[39m\u001b[33m'\u001b[39m\u001b[33mq\u001b[39m\u001b[33m'\u001b[39m\u001b[33m для остановки.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "\n",
    "os.makedirs(\"data/images\", exist_ok=True)\n",
    "\n",
    "cap = cv2.VideoCapture(\"https://restreamer.vms.evo73.ru/918335436b92ac26/stream.m3u8\")\n",
    "count = 0\n",
    "\n",
    "print(\"Сбор кадров начат... Нажми 'q' для остановки.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        if count % 60 == 0:  # один кадр каждые 2 сек (30 FPS)\n",
    "            cv2.imwrite(f\"data/images/frame_{count}.jpg\", frame)\n",
    "            print(f\"Сохранён кадр {count}\")\n",
    "        count += 1\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q') or count > 500:  # 500 кадров\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05094132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется: cpu\n",
      "Ultralytics 8.3.176  Python-3.12.6 torch-2.8.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=0.25, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.5, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov10n_bus_stop_finetuned, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\train\\yolov10n_bus_stop_finetuned, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
      " 23        [16, 19, 22]  1    861718  ultralytics.nn.modules.head.v10Detect        [1, [64, 128, 256]]           \n",
      "YOLOv10n summary: 223 layers, 2,707,430 parameters, 2,707,414 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 493/595 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 629.485.2 MB/s, size: 1070.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning E:\\AIM\\AI-Flow-Detecting\\ai-core\\data\\train\\labels.cache... 0 images, 5 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Labels are missing or empty in E:\\AIM\\AI-Flow-Detecting\\ai-core\\data\\train\\labels.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 559.577.1 MB/s, size: 1070.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\AIM\\AI-Flow-Detecting\\ai-core\\data\\val\\labels.cache... 0 images, 5 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Labels are missing or empty in E:\\AIM\\AI-Flow-Detecting\\ai-core\\data\\val\\labels.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\train\\yolov10n_bus_stop_finetuned\\labels.jpg... \n",
      "WARNING zero-size array to reduction operation maximum which has no identity\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\yolov10n_bus_stop_finetuned\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "       1/10         0G          0      76.07          0          0        640: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5          0          0          0          0          0\n",
      "WARNING no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G          0      55.99          0          0        640: 100%|██████████| 1/1 [00:03<00:00,  3.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5          0          0          0          0          0\n",
      "WARNING no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G          0      41.48          0          0        640: 100%|██████████| 1/1 [00:02<00:00,  2.81s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5          0          0          0          0          0\n",
      "WARNING no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G          0      30.79          0          0        640: 100%|██████████| 1/1 [00:02<00:00,  2.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5          0          0          0          0          0\n",
      "WARNING no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G          0      23.03          0          0        640: 100%|██████████| 1/1 [00:02<00:00,  2.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5          0          0          0          0          0\n",
      "WARNING no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G          0      17.22          0          0        640: 100%|██████████| 1/1 [00:02<00:00,  2.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5          0          0          0          0          0\n",
      "WARNING no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G          0      12.96          0          0        640: 100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5          0          0          0          0          0\n",
      "WARNING no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G          0      9.733          0          0        640: 100%|██████████| 1/1 [00:02<00:00,  2.90s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5          0          0          0          0          0\n",
      "WARNING no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G          0        7.4          0          0        640: 100%|██████████| 1/1 [00:03<00:00,  3.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5          0          0          0          0          0\n",
      "WARNING no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G          0      5.657          0          0        640: 100%|██████████| 1/1 [00:02<00:00,  2.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5          0          0          0          0          0\n",
      "WARNING no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs\\train\\yolov10n_bus_stop_finetuned\\weights\\last.pt, 5.7MB\n",
      "Optimizer stripped from runs\\train\\yolov10n_bus_stop_finetuned\\weights\\best.pt, 5.7MB\n",
      "\n",
      "Validating runs\\train\\yolov10n_bus_stop_finetuned\\weights\\best.pt...\n",
      "Ultralytics 8.3.176  Python-3.12.6 torch-2.8.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 102 layers, 2,265,363 parameters, 0 gradients, 6.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Model does not support 'augment=True', reverting to single-scale prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.05it/s]\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:668: RuntimeWarning: Mean of empty slice.\n",
      "  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:713: RuntimeWarning: Mean of empty slice.\n",
      "  y = smooth(py.mean(0), 0.1)\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:713: RuntimeWarning: Mean of empty slice.\n",
      "  y = smooth(py.mean(0), 0.1)\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:713: RuntimeWarning: Mean of empty slice.\n",
      "  y = smooth(py.mean(0), 0.1)\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "e:\\AIM\\AI-Flow-Detecting\\ai-core\\mai\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:850: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          5          0          0          0          0          0\n",
      "WARNING no labels found in detect set, can not compute metrics without labels\n",
      "Speed: 0.9ms preprocess, 59.9ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\train\\yolov10n_bus_stop_finetuned\u001b[0m\n",
      "✅ Модель дообучена и сохранена.\n"
     ]
    }
   ],
   "source": [
    "# train.py\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# Выбираем устройство\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Используется: {device}\")\n",
    "\n",
    "# Загружаем предобученную модель\n",
    "model = YOLO('yolov10n.pt')  # можно yolov8s.pt для точности\n",
    "\n",
    "# Обучение\n",
    "model.train(\n",
    "    data='data.yaml',        # см. ниже\n",
    "    epochs=10,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    device=device,\n",
    "    name='yolov10n_bus_stop_finetuned',\n",
    "    augment=True,\n",
    "    patience=15,\n",
    "    optimizer='AdamW',\n",
    "    lr0=1e-3,\n",
    "    iou=0.5,\n",
    "    conf=0.25,\n",
    "    project='runs/train'\n",
    ")\n",
    "\n",
    "# Сохранение\n",
    "model.save('models/yolov10n_best.pt')\n",
    "print(\"✅ Модель дообучена и сохранена.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95b8d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Обработка начата. Нажмите 'q' для остановки.\n"
     ]
    }
   ],
   "source": [
    "# detect_on_stream.py\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# -------------------------------\n",
    "# ### Конфигурации\n",
    "# -------------------------------\n",
    "MODEL_PATH = 'runs/train/yolov10n_bus_stop_finetuned/weights/best.pt'  # твоя дообученная модель\n",
    "STREAM_URL = \"https://restreamer.vms.evo73.ru/918335436b92ac26/stream.m3u8\"\n",
    "CONF_LEVEL = 0.6\n",
    "SCALE_PERCENT = 100\n",
    "VIDEO_NAME = \"result.mp4\"\n",
    "ROI_POINTS = np.array([(1620, 750), (750, 450), (750, 600), (1620, 950)], np.int32)\n",
    "ALPHA = 0.1\n",
    "PATIENCE = 100\n",
    "FRAME_MAX = 5\n",
    "THR_CENTERS = 25\n",
    "\n",
    "# -------------------------------\n",
    "# Загрузка модели\n",
    "# -------------------------------\n",
    "model = YOLO(MODEL_PATH)\n",
    "dict_classes = model.model.names\n",
    "\n",
    "# -------------------------------\n",
    "# Открываем поток\n",
    "# -------------------------------\n",
    "cap = cv2.VideoCapture(STREAM_URL)\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Не удалось открыть поток\")\n",
    "    exit()\n",
    "\n",
    "# Параметры видео\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "if SCALE_PERCENT != 100:\n",
    "    width = int(width * SCALE_PERCENT / 100)\n",
    "    height = int(height * SCALE_PERCENT / 100)\n",
    "\n",
    "# -------------------------------\n",
    "# VideoWriter\n",
    "# -------------------------------\n",
    "tmp_out = \"tmp_result.mp4\"\n",
    "output_out = \"rep_result.mp4\"\n",
    "\n",
    "if os.path.exists(tmp_out): os.remove(tmp_out)\n",
    "if os.path.exists(output_out): os.remove(output_out)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(tmp_out, fourcc, fps, (width, height))\n",
    "\n",
    "# -------------------------------\n",
    "# Вспомогательные функции\n",
    "# -------------------------------\n",
    "def resize_frame(frame, scale):\n",
    "    if scale == 100: return frame\n",
    "    w = int(frame.shape[1] * scale / 100)\n",
    "    h = int(frame.shape[0] * scale / 100)\n",
    "    return cv2.resize(frame, (w, h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def update_tracking(centers_old, center, thr, last_key, frame_idx, frame_max):\n",
    "    best_id = None\n",
    "    min_dist = float('inf')\n",
    "    for obj_id, history in centers_old.items():\n",
    "        last_center = list(history.keys())[-1]\n",
    "        dist = np.linalg.norm(np.array(last_center) - np.array(center))\n",
    "        if dist < thr and dist < min_dist:\n",
    "            min_dist = dist\n",
    "            best_id = obj_id\n",
    "\n",
    "    if best_id is not None:\n",
    "        centers_old[best_id][center] = frame_idx\n",
    "        return centers_old, best_id, False, best_id\n",
    "    else:\n",
    "        new_id = f\"p_{len(centers_old)}\"\n",
    "        centers_old[new_id] = {center: frame_idx}\n",
    "        return centers_old, new_id, True, new_id\n",
    "\n",
    "def filter_tracks(centers_old, patience):\n",
    "    current_frame = max([max(t.values()) for t in centers_old.values()] + [0])\n",
    "    to_remove = [k for k, v in centers_old.items() if current_frame - max(v.values()) > patience]\n",
    "    for k in to_remove:\n",
    "        del centers_old[k]\n",
    "    return centers_old\n",
    "\n",
    "# -------------------------------\n",
    "# Основной цикл\n",
    "# -------------------------------\n",
    "centers_old = {}\n",
    "total_count = 0\n",
    "frame_idx = 0\n",
    "\n",
    "print(\"✅ Обработка начата. Нажмите 'q' для остановки.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"⚠️ Кадр не получен. Переподключение...\")\n",
    "        cap.release()\n",
    "        cap = cv2.VideoCapture(STREAM_URL)\n",
    "        continue\n",
    "\n",
    "    frame_idx += 1\n",
    "    frame = resize_frame(frame, SCALE_PERCENT)\n",
    "    display_frame = frame.copy()\n",
    "\n",
    "    # --- ROI ---\n",
    "    overlay = display_frame.copy()\n",
    "    cv2.polylines(overlay, [ROI_POINTS], True, (255, 0, 0), 2)\n",
    "    cv2.fillPoly(overlay, [ROI_POINTS], (255, 0, 0))\n",
    "    cv2.addWeighted(overlay, ALPHA, display_frame, 1 - ALPHA, 0, display_frame)\n",
    "\n",
    "    # Вырезаем ROI\n",
    "    x_min, y_min = ROI_POINTS[:, 0].min(), ROI_POINTS[:, 1].min()\n",
    "    x_max, y_max = ROI_POINTS[:, 0].max(), ROI_POINTS[:, 1].max()\n",
    "    roi_frame = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    # --- Детекция ---\n",
    "    results = model(roi_frame, conf=CONF_LEVEL, classes=[0], verbose=False)\n",
    "    if len(results[0].boxes) == 0:\n",
    "        detections = pd.DataFrame(columns=['xmin', 'ymin', 'xmax', 'ymax', 'conf'])\n",
    "    else:\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "        conf = results[0].boxes.conf.cpu().numpy()\n",
    "        detections = pd.DataFrame(np.column_stack([boxes, conf]),\n",
    "                                  columns=['xmin', 'ymin', 'xmax', 'ymax', 'conf'])\n",
    "\n",
    "    # --- Обработка каждого человека ---\n",
    "    for _, row in detections.iterrows():\n",
    "        xmin, ymin, xmax, ymax, conf_val = map(int, row)\n",
    "        cx = (xmin + xmax) // 2 + x_min\n",
    "        cy = (ymin + ymax) // 2 + y_min\n",
    "\n",
    "        centers_old, obj_id, is_new, _ = update_tracking(\n",
    "            centers_old, (cx, cy), THR_CENTERS, None, frame_idx, FRAME_MAX\n",
    "        )\n",
    "        total_count += is_new\n",
    "\n",
    "        # Рисуем\n",
    "        cv2.rectangle(display_frame, (xmin + x_min, ymin + y_min), (xmax + x_min, ymax + y_min), (0, 255, 0), 2)\n",
    "        cv2.circle(display_frame, (cx, cy), 5, (0, 255, 0), -1)\n",
    "        cv2.putText(display_frame, f\"{obj_id} ({conf_val:.2f})\", (xmin + x_min, ymin + y_min - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)\n",
    "\n",
    "    # Фильтрация\n",
    "    centers_old = filter_tracks(centers_old, PATIENCE)\n",
    "\n",
    "    # Счётчик\n",
    "    cv2.putText(display_frame, f\"Людей в зоне: {total_count}\", (30, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 2)\n",
    "\n",
    "    # Запись и отображение\n",
    "    out.write(display_frame)\n",
    "    cv2.imshow(\"YOLOv8 — Пассажиропоток\", display_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# -------------------------------\n",
    "# Финализация\n",
    "# -------------------------------\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Перекодировка\n",
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-i\", tmp_out,\n",
    "    \"-crf\", \"18\", \"-preset\", \"veryfast\",\n",
    "    \"-vcodec\", \"libx264\", output_out\n",
    "], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "os.remove(tmp_out)\n",
    "print(f\"✅ Видео сохранено: {output_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27cb533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] - Original Dim: 1920x1080, FPS: 25.0\n",
      "✅ Начало обработки видеопотока. Нажмите 'q' для остановки.\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'obj_id' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnboundLocalError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 190\u001b[39m\n\u001b[32m    187\u001b[39m center_x += x_min\n\u001b[32m    188\u001b[39m center_y += y_min\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m centers_old, obj_id, is_new, lastKey = \u001b[43mupdate_tracking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcenters_old\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcenter_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthr_centers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlastKey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_max\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m count_p += is_new\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Рисуем bounding box и центр\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 118\u001b[39m, in \u001b[36mupdate_tracking\u001b[39m\u001b[34m(centers_old, current_center, threshold, lastKey, frame_idx, frame_max)\u001b[39m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m centers_old, best_key, \u001b[38;5;28;01mFalse\u001b[39;00m, best_key\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    117\u001b[39m     \u001b[38;5;66;03m# Новый объект\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     new_id = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mperson_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mobj_id\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    119\u001b[39m     centers_old[new_id] = {(center_x, center_y): frame_idx}\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m centers_old, new_id, \u001b[38;5;28;01mTrue\u001b[39;00m, new_id\n",
      "\u001b[31mUnboundLocalError\u001b[39m: cannot access local variable 'obj_id' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------------------\n",
    "# ### Configurations\n",
    "# -------------------------------\n",
    "verbose = False\n",
    "scale_percent = 100  # масштабирование кадра\n",
    "conf_level = 0.8     # порог уверенности\n",
    "thr_centers = 20     # порог для сопоставления центров\n",
    "frame_max = 5        # макс. кадров до \"потери\" объекта\n",
    "patience = 100       # макс. длина истории треков\n",
    "alpha = 0.1          # прозрачность ROI\n",
    "video_name = 'result.mp4'\n",
    "\n",
    "# URL видеопотока\n",
    "stream_url = \"https://restreamer.vms.evo73.ru/918335436b92ac26/stream.m3u8\"\n",
    "\n",
    "# Загрузка модели\n",
    "model = YOLO('yolov8n.pt')  # или yolov10n.pt\n",
    "\n",
    "# Классы: только люди\n",
    "class_IDS = [0]\n",
    "dict_classes = {0: 'person'}\n",
    "\n",
    "# Вспомогательные переменные\n",
    "centers_old = {}\n",
    "obj_id = 0\n",
    "count_p = 0\n",
    "lastKey = ''\n",
    "\n",
    "# -------------------------------\n",
    "# Открываем видеопоток\n",
    "# -------------------------------\n",
    "cap = cv2.VideoCapture(stream_url)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Ошибка: Не удалось открыть видеопоток.\")\n",
    "    exit()\n",
    "\n",
    "# Параметры видео\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print(f'[INFO] - Original Dim: {width}x{height}, FPS: {fps}')\n",
    "\n",
    "# Масштабирование (если нужно)\n",
    "if scale_percent != 100:\n",
    "    width = int(width * scale_percent / 100)\n",
    "    height = int(height * scale_percent / 100)\n",
    "    print(f'[INFO] - Dim Scaled: {width}x{height}')\n",
    "\n",
    "# Функция для изменения размера кадра\n",
    "def risize_frame(frame, scale_percent):\n",
    "    if scale_percent == 100:\n",
    "        return frame\n",
    "    width_new = int(frame.shape[1] * scale_percent / 100)\n",
    "    height_new = int(frame.shape[0] * scale_percent / 100)\n",
    "    return cv2.resize(frame, (width_new, height_new), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# -------------------------------\n",
    "# Настройка записи видео\n",
    "# -------------------------------\n",
    "output_path = \"rep_\" + video_name\n",
    "tmp_output_path = \"tmp_\" + output_path\n",
    "\n",
    "# Удаляем старые файлы\n",
    "for f in [tmp_output_path, output_path]:\n",
    "    if os.path.exists(f):\n",
    "        os.remove(f)\n",
    "\n",
    "VIDEO_CODEC = cv2.VideoWriter_fourcc(*\"MP4V\")\n",
    "output_video = cv2.VideoWriter(tmp_output_path, VIDEO_CODEC, fps, (width, height))\n",
    "\n",
    "if not output_video.isOpened():\n",
    "    print(\"❌ Ошибка: Не удалось инициализировать VideoWriter.\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "# -------------------------------\n",
    "# ROI: область интереса (остановка)\n",
    "# -------------------------------\n",
    "def get_roi_points():\n",
    "    # Пример: треугольник или трапеция на остановке\n",
    "    # Адаптируй под свою камеру!\n",
    "    return [np.array([(1250, 400), (750, 400), (700, 800), (1200, 800)], np.int32)]\n",
    "\n",
    "# -------------------------------\n",
    "# Функция обновления трекинга\n",
    "# -------------------------------\n",
    "def update_tracking(centers_old, current_center, threshold, lastKey, frame_idx, frame_max):\n",
    "    center_x, center_y = current_center\n",
    "    is_new = False\n",
    "    min_dist = float('inf')\n",
    "    best_key = None\n",
    "\n",
    "    for obj_id, centers in centers_old.items():\n",
    "        # Последний известный центр\n",
    "        last_center = list(centers.keys())[-1]\n",
    "        cx, cy = last_center\n",
    "        dist = np.sqrt((cx - center_x)**2 + (cy - center_y)**2)\n",
    "        if dist < min_dist and dist < threshold:\n",
    "            min_dist = dist\n",
    "            best_key = obj_id\n",
    "\n",
    "    if best_key is not None:\n",
    "        # Обновляем трек\n",
    "        centers_old[best_key][(center_x, center_y)] = frame_idx\n",
    "        return centers_old, best_key, False, best_key\n",
    "    else:\n",
    "        # Новый объект\n",
    "        new_id = f\"person_{obj_id}\"\n",
    "        centers_old[new_id] = {(center_x, center_y): frame_idx}\n",
    "        return centers_old, new_id, True, new_id\n",
    "\n",
    "# -------------------------------\n",
    "# Фильтрация старых треков\n",
    "# -------------------------------\n",
    "def filter_tracks(centers_old, patience):\n",
    "    current_frame = max([max(frames.values()) for frames in centers_old.values()] + [0]) if centers_old else 0\n",
    "    keys_to_remove = []\n",
    "    for obj_id, centers in centers_old.items():\n",
    "        last_seen = max(centers.values())\n",
    "        if current_frame - last_seen > patience:\n",
    "            keys_to_remove.append(obj_id)\n",
    "    for k in keys_to_remove:\n",
    "        del centers_old[k]\n",
    "    return centers_old\n",
    "\n",
    "# -------------------------------\n",
    "# Основной цикл обработки потока\n",
    "# -------------------------------\n",
    "print(\"✅ Начало обработки видеопотока. Нажмите 'q' для остановки.\")\n",
    "\n",
    "frame_count = 0\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"⚠️ Не удалось получить кадр. Попытка переподключения...\")\n",
    "            time.sleep(2)\n",
    "            cap.release()\n",
    "            cap = cv2.VideoCapture(stream_url)\n",
    "            continue\n",
    "\n",
    "        frame_count += 1\n",
    "        frame = risize_frame(frame, scale_percent)\n",
    "        overlay = frame.copy()\n",
    "\n",
    "        # --- ROI ---\n",
    "        area_roi = get_roi_points()\n",
    "        cv2.polylines(overlay, pts=area_roi, isClosed=True, color=(255, 0, 0), thickness=2)\n",
    "        cv2.fillPoly(overlay, area_roi, (255, 0, 0))\n",
    "        frame = cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0)\n",
    "\n",
    "        # Вырезаем ROI\n",
    "        x_min = min([p[0] for p in area_roi[0]])\n",
    "        x_max = max([p[0] for p in area_roi[0]])\n",
    "        y_min = min([p[1] for p in area_roi[0]])\n",
    "        y_max = max([p[1] for p in area_roi[0]])\n",
    "        roi_frame = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "        # --- Детекция ---\n",
    "        results = model.predict(roi_frame, conf=conf_level, classes=class_IDS, verbose=False)\n",
    "        if len(results[0].boxes) == 0:\n",
    "            positions_frame = pd.DataFrame(columns=['xmin', 'ymin', 'xmax', 'ymax', 'conf', 'class'])\n",
    "        else:\n",
    "            boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "            conf = results[0].boxes.conf.cpu().numpy()\n",
    "            classes = results[0].boxes.cls.cpu().numpy()\n",
    "            positions_frame = pd.DataFrame(np.column_stack([boxes, conf, classes]),\n",
    "                                           columns=['xmin', 'ymin', 'xmax', 'ymax', 'conf', 'class'])\n",
    "\n",
    "        # --- Обработка каждого человека ---\n",
    "        for idx, row in positions_frame.iterrows():\n",
    "            xmin, ymin, xmax, ymax, conf_val, cls = map(int, row[:6])\n",
    "            center_x = (xmin + xmax) // 2\n",
    "            center_y = (ymin + ymax) // 2\n",
    "\n",
    "            # Смещение центра в глобальные координаты\n",
    "            center_x += x_min\n",
    "            center_y += y_min\n",
    "\n",
    "            centers_old, obj_id, is_new, lastKey = update_tracking(\n",
    "                centers_old, (center_x, center_y), thr_centers, lastKey, frame_count, frame_max\n",
    "            )\n",
    "            count_p += is_new\n",
    "\n",
    "            # Рисуем bounding box и центр\n",
    "            cv2.rectangle(frame, (xmin + x_min, ymin + y_min), (xmax + x_min, ymax + y_min), (0, 0, 255), 2)\n",
    "            cv2.circle(frame, (center_x, center_y), 5, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, f\"{obj_id}:{conf_val:.2f}\", (xmin + x_min, ymin + y_min - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 1)\n",
    "\n",
    "        # --- Фильтрация старых треков ---\n",
    "        centers_old = filter_tracks(centers_old, patience)\n",
    "\n",
    "        # --- Отображение счётчика ---\n",
    "        cv2.putText(frame, f'People in ROI: {count_p}', (30, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 0, 0), 2)\n",
    "\n",
    "        # --- Запись кадра ---\n",
    "        output_video.write(frame)\n",
    "\n",
    "        # --- Показываем результат ---\n",
    "        cv2.imshow(\"Live Detection\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF in [ord('q'), ord(' ')]:\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"⏹️ Остановлено пользователем.\")\n",
    "\n",
    "# -------------------------------\n",
    "# Финализация: перекодировка видео\n",
    "# -------------------------------\n",
    "output_video.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"🔁 Перекодировка видео для совместимости...\")\n",
    "\n",
    "if os.path.exists(output_path):\n",
    "    os.remove(output_path)\n",
    "\n",
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-i\", tmp_output_path,\n",
    "    \"-crf\", \"18\",\n",
    "    \"-preset\", \"veryfast\",\n",
    "    \"-hide_banner\", \"-loglevel\", \"error\",\n",
    "    \"-vcodec\", \"libx264\", output_path\n",
    "], check=True)\n",
    "\n",
    "os.remove(tmp_output_path)\n",
    "print(f\"✅ Видео сохранено: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8495eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking samples of processed frames\n",
    "for i in [62,63, 64, 65, 66]:\n",
    "    plt.figure(figsize =( 14, 10))\n",
    "    plt.imshow(frames_list[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1afbe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output video result\n",
    "frac = 0.7 \n",
    "Video(data='rep_result.mp4', embed=True, height=int(720 * frac), width=int(1280 * frac))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mai (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
